{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HuiHAN0601/AVH-TFLmicrospeech/blob/main/cod_hackathon_hui.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxD-k31RtrFb"
      },
      "source": [
        "# To assign each CoD string from the 'frequency_tidy_cod_hackathon.csv' file the correct CoD code from the 'DK1875.csv' file using Natural Language Processing (NLP) techniques, following these steps:\n",
        "\n",
        "1. Preprocess the data:\n",
        "Read the 'frequency_tidy_cod_hackathon.csv' and 'DK1875.csv' files and load them into appropriate data structures, such as pandas dataframes. Perform any necessary data cleaning and preprocessing steps, such as removing missing values, standardizing text formats, and handling language variations.\n",
        "\n",
        "2. Define a similarity measure:\n",
        "Determine a similarity measure to compare the CoD strings from 'frequency_tidy_cod_hackathon.csv' with the 'latin_name' and 'danish_name' columns from 'DK1875.csv'. I use NLP techniques for similarity: Word Embedding Similarity\n",
        "\n",
        "3. Perform matching:\n",
        "Iterate over each CoD string in 'frequency_tidy_cod_hackathon.csv'.\n",
        "Calculate the similarity score between the CoD string and the 'latin_name' and 'danish_name' columns in 'DK1875.csv' using the chosen similarity measure. Assign the CoD code based on the highest similarity score or a predefined threshold.\n",
        "\n",
        "4. Evaluate and validate the results:\n",
        "Compare the assigned CoD codes with the original codes in 'DK1875.csv' to evaluate the accuracy of the matching process. Assess any discrepancies or potential errors and make necessary adjustments."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yyIz3yJntrFd"
      },
      "source": [
        "1. Preprocess the data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Specify the file paths\n",
        "frequency_file_path = '/content/drive/MyDrive/frequency_tidy_cod_hackathon.csv'\n",
        "dk1875_file_path = '/content/drive/MyDrive/DK1875.csv'\n",
        "\n",
        "# Load the data from the CSV files\n",
        "frequency_df = pd.read_csv(frequency_file_path, sep=';', header=None)\n",
        "dk1875_df = pd.read_csv(dk1875_file_path, sep=';', header=None)\n"
      ],
      "metadata": {
        "id": "25LGXEQ7wVZp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Specify the file paths\n",
        "frequency_file_path = '/content/drive/MyDrive/frequency_tidy_cod_hackathon.csv'\n",
        "dk1875_file_path = '/content/drive/MyDrive/DK1875.csv'\n",
        "\n",
        "# Load the data from the CSV files\n",
        "frequency_df = pd.read_csv(frequency_file_path, sep=';', header=None)\n",
        "dk1875_df = pd.read_csv(dk1875_file_path, sep=';', header=None)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWdvKKU6dCqP",
        "outputId": "b6c7132a-9ed2-4a0d-ce63-ba3a627b8c59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lPw1egGjtrFf",
        "outputId": "e2b69618-02c3-416a-fb8a-b2799e44f213"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                       0\n",
            "0                               tidy_cod\n",
            "1  morbus cordis (mb. cordis, mb. cord.)\n",
            "2                                dødfødt\n",
            "3                   pneumonia (pneumoni)\n",
            "4                       bronchopneumonia\n",
            "                                       0\n",
            "0  DK_Danish_Code$latin_name$danish_name\n",
            "1                       1$Variolæ$Kopper\n",
            "2                   2$Morbilli$Mæslinger\n",
            "3           3$Scarlatina$Skarlagensfeber\n",
            "4       4$Diphtheritis$Ondartet Halssyge\n"
          ]
        }
      ],
      "source": [
        "# Perform basic data exploration to understand the structure and contents of the dataframes.\n",
        "print(frequency_df.head())\n",
        "print(dk1875_df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-blIe5QtrFg"
      },
      "source": [
        "2. Define a similarity measure"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0sNektiPtrFg"
      },
      "source": [
        "Using word embeddings for similarity measurement can be a powerful approach for assigning CoD codes based on the 'latin_name' and 'danish_name' columns in the 'DK1875.csv' file. Here's how we can leverage word embeddings to calculate similarity:\n",
        "\n",
        "✻ Preprocess the text:\n",
        "Convert the CoD strings, 'latin_name', and 'danish_name' columns to lowercase and remove any leading/trailing whitespaces or punctuation marks.\n",
        "Tokenize the text by splitting it into individual words or subwords.\n",
        "\n",
        "✻ Load pre-trained word embeddings:\n",
        "Download and load a pre-trained word embedding model FastText.\n",
        "These models map words to dense vector representations in a continuous vector space, capturing semantic and contextual similarities.\n",
        "\n",
        "✻ Convert text to word embeddings:\n",
        "Iterate over the CoD strings, 'latin_name', and 'danish_name' values.\n",
        "For each text, represent it as a vector by averaging the word embeddings of its constituent words.\n",
        "You can use the pre-trained word embedding model to obtain the vector representation for each word.\n",
        "\n",
        "✻ Calculate similarity:\n",
        "Use a similarity metric like cosine similarity or Euclidean distance to compare the vector representations of the CoD strings with the 'latin_name' and 'danish_name' vectors.\n",
        "Cosine similarity is a common choice, as it measures the cosine of the angle between two vectors, indicating their similarity.\n",
        "Higher cosine similarity scores indicate greater similarity between the CoD string and the 'latin_name' or 'danish_name'."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BECJv2FtrFh"
      },
      "source": [
        "To use FastText word embeddings for Danish and Latin, we'll need to download the respective pre-trained models from the FastText website (https://fasttext.cc/docs/en/pretrained-vectors.html). Then, save the downloaded models to a local directory. Make sure to update the file paths in the code to point to the locally saved models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IsdGy9rNtrFh"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import urllib.request\n",
        "\n",
        "\n",
        "# Step 1: Load the FastText word embedding models for Danish and Latin\n",
        "\n",
        "import fasttext.util\n",
        "import zipfile\n",
        "\n",
        "# Specify the paths to the Danish and Latin model zip files in Google Drive\n",
        "danish_model_zip_path = '/content/drive/MyDrive/wiki.da.zip'\n",
        "latin_model_zip_path = '/content/drive/MyDrive/wiki.la.zip'\n",
        "\n",
        "# Extract the Danish model files from the zip file\n",
        "with zipfile.ZipFile(danish_model_zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/danish_model')\n",
        "\n",
        "# Extract the Latin model files from the zip file\n",
        "with zipfile.ZipFile(latin_model_zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/latin_model')\n",
        "\n",
        "# Load the Danish FastText model\n",
        "danish_model_path = '/content/danish_model/wiki.da.bin'\n",
        "danish_model = fasttext.load_model(danish_model_path)\n",
        "\n",
        "# Load the Latin FastText model\n",
        "latin_model_path = '/content/latin_model/wiki.la.bin'\n",
        "latin_model = fasttext.load_model(latin_model_path)\n",
        "\n",
        "\n",
        "# Step 2: Load the CoD strings from 'frequency_tidy_cod_hackathon.csv'\n",
        "cod_strings = []\n",
        "with open('frequency_tidy_cod_hackathon.csv', 'r') as file:\n",
        "    reader = csv.reader(file)\n",
        "    next(reader)  # Skip the header row\n",
        "    for row in reader:\n",
        "        cod_strings.append(row[0])\n",
        "\n",
        "# Step 3: Load the CoD codes and names from 'DK1875.csv'\n",
        "cod_mapping = {}\n",
        "with open('DK1875.csv', 'r') as file:\n",
        "    reader = csv.reader(file)\n",
        "    next(reader)  # Skip the header row\n",
        "    for row in reader:\n",
        "        latin_name = row[0]\n",
        "        danish_name = row[0]\n",
        "        cod = row[0]\n",
        "        cod_mapping[cod] = {'latin_name': latin_name, 'danish_name': danish_name}\n",
        "\n",
        "# Step 4: Assign CoD codes based on similarity\n",
        "results = []\n",
        "for cod_string in cod_strings:\n",
        "    best_similarity = -1\n",
        "    best_cod = None\n",
        "\n",
        "    for cod, cod_data in cod_mapping.items():\n",
        "        latin_name = cod_data['latin_name']\n",
        "        danish_name = cod_data['danish_name']\n",
        "\n",
        "        similarity_latin = danish_model.get_word_vector(cod_string).dot(danish_model.get_word_vector(latin_name))\n",
        "        similarity_danish = latin_model.get_word_vector(cod_string).dot(latin_model.get_word_vector(danish_name))\n",
        "        similarity = max(similarity_latin, similarity_danish)\n",
        "\n",
        "        if similarity > best_similarity:\n",
        "            best_similarity = similarity\n",
        "            best_cod = cod\n",
        "\n",
        "    results.append((cod_string, best_cod))\n",
        "\n",
        "# Step 5: Save the results in a new file or data structure\n",
        "with open('assigned_cod_codes.csv', 'w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow(['CoD String', 'CoD Code'])\n",
        "    writer.writerows(results)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Download the file\n",
        "files.download('assigned_cod_codes.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "id": "VSYuEtpIg023",
        "outputId": "9084b5a0-e722-4b27-ea72-9a8b114d8334"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-8fa80a2ab288>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Download the file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'assigned_cod_codes.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    223\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m     \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Cannot find file: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=undefined-variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m   \u001b[0mcomm_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_IPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomm_manager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: Cannot find file: assigned_cod_codes.csv"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Specify the file path\n",
        "output_file_path = '/Users/huihan/Desktop/frequency_tidy_cod_hackathon_assigned.csv'\n",
        "\n",
        "# Save the DataFrame as a CSV file\n",
        "frequency_df.to_csv(output_file_path, index=False)\n",
        "\n",
        "# Check if the file was created successfully\n",
        "if os.path.isfile(output_file_path):\n",
        "    print(\"CSV file saved successfully.\")\n",
        "else:\n",
        "    print(\"Failed to save the CSV file.\")"
      ],
      "metadata": {
        "id": "hvOx2JY5gdAU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NF-_ZnBmtrFh",
        "outputId": "0cea539a-ee1b-4773-b24f-5d989a26c86b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fuzzywuzzy\n",
            "  Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl (18 kB)\n",
            "Installing collected packages: fuzzywuzzy\n",
            "Successfully installed fuzzywuzzy-0.18.0\n"
          ]
        }
      ],
      "source": [
        "!pip3 install fuzzywuzzy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        },
        "id": "cyBgDr8UtrFi",
        "outputId": "b7b2cac6-5a8d-4f89-d281-4f65d3e4bce2"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3802\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3803\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.index.Int64Engine._check_type\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'tidy_cod'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-ba43f8b595d2>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Iterate over each CoD string in 'frequency_df'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfrequency_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mcod_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tidy_cod'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mhighest_similarity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mmatched_cod_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    979\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 981\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1087\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1088\u001b[0m         \u001b[0;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1089\u001b[0;31m         \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1090\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values_for_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3803\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3804\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3805\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3806\u001b[0m                 \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'tidy_cod'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from fuzzywuzzy import fuzz\n",
        "\n",
        "\n",
        "# Iterate over each CoD string in 'frequency_df'\n",
        "for index, row in frequency_df.iterrows():\n",
        "    cod_string = row['tidy_cod']\n",
        "    highest_similarity = 0\n",
        "    matched_cod_code = None\n",
        "\n",
        "    # Iterate over each row in 'dk1875_df'\n",
        "    for dk_index, dk_row in dk1875_df.iterrows():\n",
        "        latin_name = dk_row['latin_name']\n",
        "        danish_name = dk_row['danish_name']\n",
        "\n",
        "        # Calculate similarity scores between the CoD string and the Latin and Danish names\n",
        "        latin_similarity = fuzz.ratio(cod_string, latin_name)\n",
        "        danish_similarity = fuzz.ratio(cod_string, danish_name)\n",
        "\n",
        "        # Update the highest similarity and matched CoD code if necessary\n",
        "        if latin_similarity > highest_similarity:\n",
        "            highest_similarity = latin_similarity\n",
        "            matched_cod_code = dk_row['DK_Danish']\n",
        "        if danish_similarity > highest_similarity:\n",
        "            highest_similarity = danish_similarity\n",
        "            matched_cod_code = dk_row['DK_Danish']\n",
        "\n",
        "    # Assign the matched CoD code to the corresponding CoD string\n",
        "    frequency_df.at[index, 'cod_code'] = matched_cod_code\n",
        "\n",
        "# Save the updated dataframe to a new file or perform further analysis\n",
        "frequency_df.to_csv('matched_cod_codes.csv', index=False)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}